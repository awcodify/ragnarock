[models.llama3_2]
routing = ["ollama"]

[models.llama3_2.providers.ollama]
type = "openai"
api_base = "http://host.docker.internal:1090/v1/"
model_name = "llama3.2"
api_key_location = "none"

[models.claude-3-5-sonnet-latest]
routing = ["anthropic"]

[models.claude-3-5-sonnet-latest.providers.anthropic]
type = "anthropic"
model_name = "claude-3-5-haiku-20241022"

[functions.generate_analysis]
type = "chat"
user_schema = "functions/generate_analysis/user_schema.json"

[functions.generate_analysis.variants.llama3_2]
type = "chat_completion"
model = "llama3_2"
user_template = "functions/generate_analysis/anthropic/user_template.minijinja"